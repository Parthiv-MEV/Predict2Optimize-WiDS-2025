{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81c523b8",
   "metadata": {},
   "source": [
    "# Week 4: Tasks\n",
    "\n",
    "1. Find helpers for visualization and loading data in `helpers.py`. Please make sure to go through them so you understand their purpose. Feel free to tweak these or add your ones.\n",
    "\n",
    "2. First approach the theoretical tasks to make sure you can understand and frame the problems correctly.\n",
    "\n",
    "3. Solve the programming tasks making use of the helpers.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49adffea",
   "metadata": {},
   "source": [
    "## Theoretical Tasks: framing convex programs\n",
    "\n",
    "Write up your solutions (brief explanations) in markdown.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343418e5",
   "metadata": {},
   "source": [
    "\n",
    "**Problem 0: Were you listening?**\n",
    "\n",
    "For each of the following optimization problems:\n",
    "1. State whether it is a **convex optimization problem** or **not**.\n",
    "2. Justify your answer briefly (one sentence is enough).\n",
    "\n",
    "#### (a)\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{x \\in \\mathbb{R}^n} \\quad & x^\\top Q x + c^\\top x \\\\\n",
    "\\text{s.t.} \\quad & Ax = b\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $Q \\succeq 0$, $A \\in \\mathbb{R}^{m \\times n}$, $b \\in \\mathbb{R}^m$.\n",
    "\n",
    "#### (b)\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{x \\in \\mathbb{R}^n} \\quad & \\|x\\|_2^2 \\\\\n",
    "\\text{s.t.} \\quad & \\|Ax\\|_2 \\ge 1\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $A \\in \\mathbb{R}^{m \\times n}$.\n",
    "\n",
    "#### (c)\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\max_{w \\in \\mathbb{R}^n} \\quad & (\\mu^\\top w)(\\mathbf{1}^\\top w) \\\\\n",
    "\\text{s.t.} \\quad & w \\ge 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\mu \\in \\mathbb{R}^n$ is fixed.\n",
    "\n",
    "---\n",
    "\n",
    "**Problem 1: Minimum-norm Feasibility**\n",
    "  \n",
    "You are given a system of linear equations $Cx=d$, where $C\\in\\mathbb{R}^{k\\times n}$ has full row rank and $d\\in\\mathbb{R}^k$.  \n",
    "Among all vectors $x$ that satisfy the constraints, you wish to select one that is in some sense “small”.\n",
    "\n",
    "1. Formulate this task as a **convex optimization problem**.\n",
    "2. Argue why the problem is feasible and has a unique solution.\n",
    "3. *(Bonus)* Derive a closed-form expression for the optimal solution.\n",
    "\n",
    "*Hints*  \n",
    "- What properties must the objective function satisfy? Try reasoning about it to come up with a metric that preserves these properties and is convex.\n",
    "- Lagrange multipliers and first-order optimality conditions are sufficient to solve the problem explicitly (part 3).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2109610",
   "metadata": {},
   "source": [
    "**(BONUS) Problem 2: Stochastic Robust Approximation**\n",
    "\n",
    "Consider a linear approximation problem in which the data matrix is uncertain. Let\n",
    "$$\n",
    "A=\\bar A+U,\n",
    "$$\n",
    "where $U$ is a random matrix with $\\mathbb{E}[U]=0$. The goal is to choose $x$ that performs well *on average* under this uncertainty.\n",
    "\n",
    "1. **Stochastic robust objective.**  \n",
    "   Consider the problem\n",
    "   $$\n",
    "   \\min_x \\; \\mathbb{E}\\,\\|Ax-b\\|.\n",
    "   $$\n",
    "   - Show that this is a convex optimization problem.  \n",
    "   - If $A$ takes finitely many values $\\{A_i\\}_{i=1}^k$ with probabilities $p_i$, rewrite the objective explicitly and express the problem as a deterministic convex program.  \n",
    "   - Comment briefly on when this formulation can be written as an LP or an SOCP, depending on the choice of norm. ([This](https://zhengy09.github.io/ECE285/lectures/L6.pdf) might help).\n",
    "\n",
    "2. **Quadratic specialization.**  \n",
    "   Now consider the least-squares variant\n",
    "   $$\n",
    "   \\min_x \\; \\mathbb{E}\\,\\|Ax-b\\|_2^2.\n",
    "   $$\n",
    "   - Show that the objective can be written as the sum of a nominal least-squares term and an additional quadratic term involving $x$.  \n",
    "   - *(Bonus $^2$)* Use this structure to derive a closed-form solution.\n",
    "\n",
    "3. **Discussion.**  \n",
    "   - How does uncertainty in $A$ influence the geometry and conditioning of the solution?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15b1b3b",
   "metadata": {},
   "source": [
    "### Problem 0\n",
    "\n",
    "**(a) Convex.**  \n",
    "The objective $x^\\top Q x + c^\\top x$ is convex when $Q \\succeq 0$, and the constraint $Ax = b$ is affine (hence defines a convex feasible set).\n",
    "\n",
    "**(b) Not convex.**  \n",
    "Although $\\|x\\|_2^2$ is convex, the constraint $\\|Ax\\|_2 \\ge 1$ is a superlevel set of a convex function, which is generally non-convex.\n",
    "\n",
    "**(c) Not convex.**  \n",
    "The objective $(\\mu^\\top w)(\\mathbf{1}^\\top w)$ is a product of two affine functions (neither convex nor concave in general), so maximizing it over $w \\ge 0$ is not a convex optimization problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92b788a",
   "metadata": {},
   "source": [
    "### Problem 1: Minimum-norm Feasibility\n",
    "\n",
    "**1. Convex formulation**\n",
    "\n",
    "A natural notion of “small” is the Euclidean norm. The problem can be formulated as\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{x \\in \\mathbb{R}^n} \\quad & \\|x\\|_2^2 \\\\\n",
    "\\text{s.t.} \\quad & Cx = d .\n",
    "\\end{aligned}\n",
    "$$\n",
    "This is a convex optimization problem since the objective is convex and the constraint is affine.\n",
    "\n",
    "**2. Feasibility and uniqueness**\n",
    "\n",
    "The problem is feasible because $C$ has full row rank, so the linear system $Cx=d$ has at least one solution.  \n",
    "The objective $\\|x\\|_2^2$ is strictly convex, hence the feasible set contains a unique minimizer.\n",
    "\n",
    "**3. (Bonus) Closed-form solution**\n",
    "\n",
    "Form the Lagrangian\n",
    "$$\n",
    "\\mathcal{L}(x,\\lambda) = \\|x\\|_2^2 + \\lambda^\\top (Cx - d).\n",
    "$$\n",
    "The first-order optimality condition with respect to $x$ gives\n",
    "$$\n",
    "2x + C^\\top \\lambda = 0 \\quad \\Rightarrow \\quad x = -\\tfrac{1}{2} C^\\top \\lambda.\n",
    "$$\n",
    "Substituting into the constraint $Cx=d$ yields\n",
    "$$\n",
    "-\\tfrac{1}{2} C C^\\top \\lambda = d\n",
    "\\quad \\Rightarrow \\quad\n",
    "\\lambda = -2 (C C^\\top)^{-1} d,\n",
    "$$\n",
    "where $C C^\\top$ is invertible since $C$ has full row rank. Therefore, the optimal solution is\n",
    "$$\n",
    "x^\\star = C^\\top (C C^\\top)^{-1} d,\n",
    "$$\n",
    "which is the minimum-norm solution of $Cx=d$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2207f90",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af11d9a7",
   "metadata": {},
   "source": [
    "## Task 0: Store week 2/3 data and read it in\n",
    "Use helpers to store your expected returns and risk data along with tickers, and read them to load them into this notebook.\n",
    "\n",
    "See usage in `intro_to_cvxpy.ipynb` in the fully solved example.\n",
    "\n",
    "NOTE: The week 2 models only predict expected returns ($\\hat\\mu$), we compute $\\hat\\Sigma$ as simple covariance matrix of the tickers' returns data for now. In reality predicting $\\hat\\Sigma$ is a big challenge (perhaps bigger than predicting $\\hat\\mu$) but we overlook those concerns for now.\n",
    "\n",
    "For eg: `Sigma_hat = np.cov(returns, rowvar=False)`, where `returns` contains the returns data series for the tickers we are studying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ed589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install cvxpy\n",
    "%pip install pd\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de725689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import (\n",
    "    save_predictions,\n",
    "    load_predictions,\n",
    "    plot_mu_and_cov,\n",
    "    visualize_weights_stacked,\n",
    "    visualize_return_risk,\n",
    "    compute_sharpe_ratios,\n",
    "    plot_sharpe_ratios,\n",
    "    print_sharpe_table,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a2a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: assuming u saved your data in `predicted.npz`\n",
    "\n",
    "# mu, Sigma, tickers = load_predictions('predicted.npz')\n",
    "\n",
    "import os\n",
    "\n",
    "candidate_paths = [\n",
    "    \"predictions.npz\",\n",
    "    \"predicted.npz\",\n",
    "    os.path.join(os.getcwd(), \"predictions.npz\"),\n",
    "    os.path.join(os.getcwd(), \"predicted.npz\"),\n",
    "]\n",
    "\n",
    "mu_hat = Sigma_hat = tickers = None\n",
    "\n",
    "for p in candidate_paths:\n",
    "    if os.path.exists(p):\n",
    "        mu_hat, Sigma_hat, tickers = load_predictions(p)\n",
    "        print(f\"Loaded predictions from: {p}\")\n",
    "        break\n",
    "\n",
    "if mu_hat is None:\n",
    "    print(\"WARNING: No predictions .npz file found. Using synthetic placeholder data.\")\n",
    "    rng = np.random.default_rng(0)\n",
    "    n_assets = 6  # TODO: set to real number of assets\n",
    "    tickers = [f\"A{i}\" for i in range(n_assets)]\n",
    "    mu_hat = rng.normal(loc=0.001, scale=0.01, size=n_assets)\n",
    "    X = rng.normal(size=(250, n_assets))\n",
    "    Sigma_hat = np.cov(X, rowvar=False)\n",
    "\n",
    "Sigma_hat = np.asarray(Sigma_hat)\n",
    "Sigma_hat = 0.5 * (Sigma_hat + Sigma_hat.T)\n",
    "Sigma_hat = Sigma_hat + 1e-10 * np.eye(len(mu_hat))\n",
    "\n",
    "print(\"mu_hat shape:\", np.asarray(mu_hat).shape)\n",
    "print(\"Sigma_hat shape:\", np.asarray(Sigma_hat).shape)\n",
    "print(\"First few tickers:\", tickers[: min(10, len(tickers))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ce12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot the data using helpers (and maybe print some lines) to confirm\n",
    "plot_mu_and_cov(mu_hat, Sigma_hat, tickers=tickers)\n",
    "df_inputs = pd.DataFrame({\"ticker\": tickers, \"mu_hat\": mu_hat})\n",
    "display(df_inputs.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108d054d",
   "metadata": {},
   "source": [
    "## Task 1. Baseline portfolios\n",
    "\n",
    "### Task 1.1 Equal weight portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491a5aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define `w_equal` to be the portfolio with equal weights on all assets\n",
    "n = len(mu_hat)\n",
    "w_equal = np.ones(n) / n\n",
    "\n",
    "print(\"Sum weights (equal):\", w_equal.sum())\n",
    "print(\"Min/Max weight (equal):\", w_equal.min(), w_equal.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeed069",
   "metadata": {},
   "source": [
    "### Task 1.2 Global Minimum Variance Portfolio, without long-only constraint\n",
    "Formally, define the problem of **minimizing $\\mathbf{w}^\\top \\Sigma \\mathbf{w}$ subject to $\\mathbf{1}^\\top \\mathbf{w} = 1$**. This gives the minimum variance portfolio, a reasonable baseline for evaluation, see Sec 6.5.1 of the book for a formal definition.\n",
    "\n",
    "(without the long-only constraint) The solution can be written analytically as:\n",
    "$$\n",
    "\\mathbf{w} = \\frac{1}{\\mathbf{1}^\\top \\Sigma^{-1} \\mathbf{1}} \\Sigma^{-1}\\mathbf{1}\n",
    "$$\n",
    "\n",
    "Compute this using numpy. This our second baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0027ec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define `w_minvar` according to above. use `np.linalg.inv` to take inverse.\n",
    "n = Sigma_hat.shape[0]\n",
    "ones = np.ones(n)\n",
    "\n",
    "Sigma_inv = np.linalg.pinv(Sigma_hat)\n",
    "w_minvar = Sigma_inv @ ones\n",
    "w_minvar = w_minvar / (ones @ w_minvar)\n",
    "\n",
    "print(\"Sum weights (GMV):\", w_minvar.sum())\n",
    "print(\"Min/Max weight (GMV):\", w_minvar.min(), w_minvar.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fa830b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2. Markowitz Optimization - Additional constraints\n",
    "\n",
    "We add two additional constraints:\n",
    "1. Leverage limit - leverage defines the \"total\" asset positions as L1 norm $|| w ||_1$.\n",
    "2. Maximum position limit - limit the maximum weight that can be placed on one asset to force diversification. For simplicity we use a scalar $u$ and enforce $|w_i| \\le u; \\forall i=1\\dots n$\n",
    "\n",
    "> Fruther on these definitions: A [paper](https://web.stanford.edu/~boyd/papers/pdf/markowitz.pdf) by Stephen Boyd, see pages 13-15.\n",
    "\n",
    "### Task 2.1: Write a helper function in similar spirit to the one in the intro notebook.\n",
    "\n",
    "Formally it should implement the following convex program:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\max_w \\quad & \\mu^\\top w - \\lambda w^\\top \\Sigma w \\\\\n",
    "\\text{s.t.}\\quad & \\mathbf{1}^\\top w = 1 & \\text{(fully invested)} \\\\\n",
    "& w \\ge \\mathbf{0} & \\text{(long only)} \\\\\n",
    "& ||w||_1 \\le \\gamma & \\text{(leverage limit)} \\\\\n",
    "\\forall i \\quad & |w_i| \\le u  & \\text{(max position limit)} \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The helper should take lambda, gamma and u as inputs along with mu and Sigma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2388eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "def markowitz_portfolio(mu, Sigma, lam, gamma=2, u=1):\n",
    "    mu = np.asarray(mu).reshape(-1)\n",
    "    Sigma = np.asarray(Sigma)\n",
    "    n = len(mu)\n",
    "\n",
    "    w = cp.Variable(n)\n",
    "\n",
    "    objective = cp.Maximize(mu @ w - lam * cp.quad_form(w, Sigma))\n",
    "    constraints = [\n",
    "        cp.sum(w) == 1,\n",
    "        w >= 0,\n",
    "        cp.norm1(w) <= gamma,\n",
    "        cp.abs(w) <= u,\n",
    "    ]\n",
    "\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "\n",
    "    solve_kwargs = {\"verbose\": verbose}\n",
    "    if solver is not None:\n",
    "        solve_kwargs[\"solver\"] = solver\n",
    "    else:\n",
    "        solve_kwargs[\"solver\"] = cp.ECOS\n",
    "\n",
    "    try:\n",
    "        problem.solve(**solve_kwargs)\n",
    "    except Exception as e:\n",
    "        print(\"ECOS failed with:\", repr(e), \"\\nFalling back to SCS...\")\n",
    "        problem.solve(solver=cp.SCS, verbose=verbose)\n",
    "\n",
    "    if w.value is None:\n",
    "        raise ValueError(f\"Optimization failed. Status: {problem.status}\")\n",
    "\n",
    "    w_opt = np.asarray(w.value).reshape(-1)\n",
    "    exp_ret = float(mu @ w_opt)\n",
    "    var = float(w_opt.T @ Sigma @ w_opt)\n",
    "    return w_opt, exp_ret, var\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bee1df",
   "metadata": {},
   "source": [
    "### Task 2.2 Vary different parameters and study the portfolios obtained\n",
    "\n",
    "As a baseline use $\\lambda = 1.2; \\; \\gamma = 1.6 \\; u = 0.8$. You may tweak this if you like.\n",
    "\n",
    "Try any subset of these; the goal is to analyze performance and possibly interpret the results to identify the best set of parameters.\n",
    "\n",
    "1. Vary $\\lambda$ over $0.01, 0.1, 1.0, 3.5, 10.0$\n",
    "2. Vary $\\gamma$ over $1.4, 1.6, 1.8$\n",
    "3. Vary $u$ over $0.6, 0.8, 0.95$\n",
    "\n",
    "Then, Collect your results as `weights, returns, variances` : 2D numpy arrays as an example:\n",
    "```python\n",
    "# demo\n",
    "lams = np.logspace(-2, 2, 15)\n",
    "\n",
    "weights = []\n",
    "returns = []\n",
    "variances = []\n",
    "\n",
    "for lam in lams:\n",
    "    w = markowitz_portfolio(mu_hat, Sigma_hat, lam)\n",
    "    weights.append(w)\n",
    "    returns.append(mu_hat @ w)\n",
    "    variances.append(w.T @ Sigma_hat @ w)\n",
    "\n",
    "weights = np.array(weights)\n",
    "returns = np.array(returns)\n",
    "variances = np.array(variances)\n",
    "```\n",
    "\n",
    "> If you're really comfortable with python you might be able to abstract this away in a wrapped functions or use decorators to prevent rewriting this same template every time. But that's not necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc291976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run for loop(s) to test out these hyperparameter tunings\n",
    "# if you would like to do a full exploration of the state space there is a python library that allows you to take cross product of sets\n",
    "\n",
    "base_lam = 1.2\n",
    "base_gamma = 1.6\n",
    "base_u = 0.8\n",
    "\n",
    "lams = [0.01, 0.1, 1.0, 3.5, 10.0]\n",
    "lam_labels = [str(x) for x in lams]\n",
    "\n",
    "weights = []\n",
    "returns = []\n",
    "variances = []\n",
    "\n",
    "for lam in lams:\n",
    "    w_opt, r, v = markowitz_portfolio(mu_hat, Sigma_hat, lam=lam, gamma=base_gamma, u=base_u)\n",
    "    weights.append(w_opt)\n",
    "    returns.append(r)\n",
    "    variances.append(v)\n",
    "\n",
    "weights = np.array(weights)\n",
    "returns = np.array(returns)\n",
    "variances = np.array(variances)\n",
    "\n",
    "print(\"weights shape:\", weights.shape)\n",
    "\n",
    "import itertools\n",
    "gammas = [1.4, 1.6, 1.8]\n",
    "us = [0.6, 0.8, 0.95]\n",
    "grid_results = []\n",
    "for lam, gamma, u in itertools.product(lams, gammas, us):\n",
    "    w_opt, r, v = markowitz_portfolio(mu_hat, Sigma_hat, lam=lam, gamma=gamma, u=u)\n",
    "    grid_results.append({\"lam\": lam, \"gamma\": gamma, \"u\": u, \"ret\": r, \"var\": v, \"w\": w_opt})\n",
    "df_grid = pd.DataFrame(grid_results)\n",
    "display(df_grid.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb0fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: visualize the portfolios using the helpers or use your own\n",
    "visualize_weights_stacked(weights, labels=lam_labels, tickers=tickers)\n",
    "\n",
    "visualize_return_risk(returns, variances, labels=lam_labels, use_volatility=True)\n",
    "\n",
    "sharpe, rets, vars_ = compute_sharpe_ratios(weights, mu_hat, Sigma_hat)\n",
    "plot_sharpe_ratios(sharpe, labels=lam_labels)\n",
    "print_sharpe_table(lam_labels, sharpe, rets, vars_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b60a1c1",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3. Robust (adversarial) optimization\n",
    "\n",
    "We now model uncertainty in predicted returns.\n",
    "\n",
    "#### Uncertainty model\n",
    "\n",
    "We assume the true return vector lies in an $\\ell_2$-ball around the predicted value:\n",
    "$$\n",
    "\\mu = \\hat\\mu + \\delta,\n",
    "\\qquad\n",
    "\\|\\delta\\|_2 \\le \\epsilon.\n",
    "$$\n",
    "\n",
    "> Note this is NOT the same as the $\\ell_\\infty$-ball error described in the README. Convince yourself that they do not correspond to the same minimization problem.\n",
    "\n",
    "The robust optimization problem is\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\max_w \\min_{\\|\\delta\\|_2 \\le \\epsilon}\n",
    "\\;& (\\hat\\mu + \\delta)^\\top w - \\lambda\\, w^\\top \\Sigma w \\\\\n",
    "\\text{s.t. } & \\mathbf{1}^\\top w = 1,\\quad w \\ge 0.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Interestingly, this reduces to the convex program\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\max_w \\;& \\hat\\mu^\\top w - \\epsilon \\|w\\|_2 - \\lambda\\, w^\\top \\Sigma w \\\\\n",
    "\\text{s.t. } & \\mathbf{1}^\\top w = 1,\\quad w \\ge 0.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This allows us to easily implement it in cvxpy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1945088e",
   "metadata": {},
   "source": [
    "### Task 3.1 - Implement the robust Markowitz solver\n",
    "Write a helper similar to task 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a076707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "def robust_markowitz(mu, Sigma, lam, eps):\n",
    "    mu = np.asarray(mu).reshape(-1)\n",
    "    Sigma = np.asarray(Sigma)\n",
    "    n = len(mu)\n",
    "\n",
    "    w = cp.Variable(n)\n",
    "\n",
    "    objective = cp.Maximize(mu @ w - eps * cp.norm(w, 2) - lam * cp.quad_form(w, Sigma))\n",
    "    constraints = [\n",
    "        cp.sum(w) == 1,\n",
    "        w >= 0,\n",
    "    ]\n",
    "\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "\n",
    "    solve_kwargs = {\"verbose\": verbose}\n",
    "    if solver is not None:\n",
    "        solve_kwargs[\"solver\"] = solver\n",
    "    else:\n",
    "        solve_kwargs[\"solver\"] = cp.ECOS\n",
    "\n",
    "    try:\n",
    "        problem.solve(**solve_kwargs)\n",
    "    except Exception as e:\n",
    "        print(\"ECOS failed with:\", repr(e), \"\\nFalling back to SCS...\")\n",
    "        problem.solve(solver=cp.SCS, verbose=verbose)\n",
    "\n",
    "    if w.value is None:\n",
    "        raise ValueError(f\"Optimization failed. Status: {problem.status}\")\n",
    "\n",
    "    w_opt = np.asarray(w.value).reshape(-1)\n",
    "    exp_ret = float(mu @ w_opt)\n",
    "    var = float(w_opt.T @ Sigma @ w_opt)\n",
    "    return w_opt, exp_ret, var\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b7216b",
   "metadata": {},
   "source": [
    "### Perturbation analysis\n",
    "\n",
    "The robust formulation provides a worst-case guarantee.\n",
    "We can analyze it with an empirical sensitivity experiment.\n",
    "\n",
    "The goal is to sample perturbations $\\delta$ uniformly from the $\\ell_2$ ball of radius $\\epsilon$ and evaluate portfolio performance under these perturbed returns.\n",
    "\n",
    "> This is similar to the kind of analysis done using Monte Carlo methods\n",
    "\n",
    "### Task 4.2 - Empirical robustness via perturbation analysis\n",
    "\n",
    "For perturbing the returns vector use this helper `sample_l2_perturbations` to generate a 2D array of perturbed vectors - our samples.\n",
    "\n",
    "> Specifically, we generate a random direction $u/||u||_2$ where $u \\sim \\mathcal{N}(0, I)$ and random length $d \\sim \\text{Uniform}(0,\\epsilon)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a279dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_l2_perturbations(n, eps, num_samples, seed=None):\n",
    "    \"\"\"\n",
    "    Sample perturbations uniformly from the l2 ball of radius eps.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    deltas = []\n",
    "    radii = []\n",
    "    for _ in range(num_samples):\n",
    "        u = np.random.randn(n)\n",
    "        u = u / np.linalg.norm(u)        # random direction\n",
    "        r = np.random.uniform(0, eps)    # random radius\n",
    "        deltas.append(r * u)\n",
    "        radii.append(r)\n",
    "\n",
    "    return np.array(deltas), np.array(radii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d442b5",
   "metadata": {},
   "source": [
    "Set $\\lambda = 1.2, \\epsilon = 0.1$, use $\\text{num\\_sample}=100$ and generate the portfolios and deltas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401c6982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: first run the markowitz_portfolio and robust_markowitz functions to get portfolios\n",
    "# remember robust_markowitz takes an additional eps parameter\n",
    "lam = 1.2\n",
    "eps = 0.1\n",
    "num_samples = 100\n",
    "seed = 0\n",
    "\n",
    "w_std, r_std, v_std = markowitz_portfolio(mu_hat, Sigma_hat, lam=lam)\n",
    "w_rob, r_rob, v_rob = robust_markowitz(mu_hat, Sigma_hat, lam=lam, eps=eps)\n",
    "\n",
    "print(\"Standard portfolio: return =\", r_std, \"volatility =\", np.sqrt(v_std))\n",
    "print(\"Robust portfolio:   return =\", r_rob, \"volatility =\", np.sqrt(v_rob))\n",
    "\n",
    "deltas, radii = sample_l2_perturbations(len(mu_hat), eps, num_samples, seed=seed)\n",
    "print(\"deltas shape:\", deltas.shape, \"radii shape:\", radii.shape)\n",
    "# solve portfolios\n",
    "#...\n",
    "\n",
    "# sample perturbations\n",
    "# NOTE: use\n",
    "#deltas, _ = sample_l2_perturbations(len(mu), eps, num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0edefb",
   "metadata": {},
   "source": [
    "Evaluate the portfolios under the list of perturbed means and collect results in 1D arrays `ret_std` and `ret_rob` (for eg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7df175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: evaluate the portfolios under perturbations and collect results\n",
    "# remember to use `mu_perturbed = mu + delta` for each delta in deltas\n",
    "\n",
    "ret_std = []\n",
    "ret_rob = []\n",
    "\n",
    "for delta in deltas:\n",
    "    mu_perturbed = mu_hat + delta\n",
    "    ret_std.append(float(mu_perturbed @ w_std))\n",
    "    ret_rob.append(float(mu_perturbed @ w_rob))\n",
    "\n",
    "ret_std = np.array(ret_std)\n",
    "ret_rob = np.array(ret_rob)\n",
    "\n",
    "print(\"Std realized returns: mean =\", ret_std.mean(), \"min =\", ret_std.min())\n",
    "print(\"Rob realized returns: mean =\", ret_rob.mean(), \"min =\", ret_rob.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba20dee0",
   "metadata": {},
   "source": [
    "Visualize your results and answer these questions:\n",
    "- Plot histograms of the data points (realized portfolio returns) in both arrays and analyze visually. What do you observe?\n",
    "- Print out summary statistics\n",
    "    - Mean, Median, Worst (minimum return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8df1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: visualize results\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.hist(ret_std, bins=20, alpha=0.6, label=\"Standard\")\n",
    "plt.hist(ret_rob, bins=20, alpha=0.6, label=\"Robust\")\n",
    "plt.xlabel(\"Realized return under perturbed mean\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of realized returns under perturbations\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "def summarize(x, name):\n",
    "    x = np.asarray(x)\n",
    "    print(f\"{name}: mean={x.mean():.6f}, median={np.median(x):.6f}, worst(min)={x.min():.6f}\")\n",
    "\n",
    "summarize(ret_std, \"Standard\")\n",
    "summarize(ret_rob, \"Robust\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170dc68e",
   "metadata": {},
   "source": [
    "### Task 4.3 (Bonus) But how poorly does standard optimization do?\n",
    "This analysis does not really show \"how\" the standard portfolio performance degrades as delta grows larger. For that we can make a scatter plot of the form\n",
    "$$(||\\delta||, \\text{realized returns on } \\hat\\mu+\\delta)$$\n",
    "For both portfolios. Try doing this and analyzing the result. Helper code is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ee7aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run the same code as above (perhaps different epsilons)\n",
    "\n",
    "# visualize results\n",
    "# NOTE: assumes radii, ret_std, ret_rob are defined from above code\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.scatter(radii, ret_std, alpha=0.5, label=\"Standard\")\n",
    "plt.scatter(radii, ret_rob, alpha=0.5, label=\"Robust\")\n",
    "\n",
    "plt.xlabel(r\"$\\|\\delta\\|_2$\")\n",
    "plt.ylabel(\"Realized return\")\n",
    "plt.title(\"Return degradation vs perturbation magnitude\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
